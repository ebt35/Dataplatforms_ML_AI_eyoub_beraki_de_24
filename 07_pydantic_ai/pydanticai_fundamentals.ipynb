{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PydanticAI fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentRunResult(output='**Name:** Linus Bergström\\n**Role:** Senior Software Developer\\n**Company:** Nordex Systems AB (fictional, but common Swedish style)\\n**Location:** Malmö, Sweden\\n**Focus:** Backend development using C#/.NET and microservices architectures, primarily on AWS. Involved in code reviews, mentoring junior developers, and contributing to architectural decisions for their logistics optimization platform.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "agent = Agent(model=\"google-gla:gemini-2.5-flash\")\n",
    "\n",
    "result = await agent.run(\"Give me an IT employee working in Sweden, no yapping\")\n",
    "\n",
    "result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Name:** Linus Bergström\n",
      "**Role:** Senior Software Developer\n",
      "**Company:** Nordex Systems AB (fictional, but common Swedish style)\n",
      "**Location:** Malmö, Sweden\n",
      "**Focus:** Backend development using C#/.NET and microservices architectures, primarily on AWS. Involved in code reviews, mentoring junior developers, and contributing to architectural decisions for their logistics optimization platform.\n"
     ]
    }
   ],
   "source": [
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use pydantic to structure output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentRunResult(output=Employee(name='Erik Karlsson', age=35, salary=65000, role='Senior Data Engineer', description='Designs, builds, and maintains scalable data pipelines and infrastructure. Expertise in ETL, data warehousing, and big data technologies.'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Employee(BaseModel):\n",
    "    name: str = Field(description=\"first name and last name of the person\")\n",
    "    age: int = Field(gt=17, lt=67, description=\"age of a person\")\n",
    "    salary: int = Field(\n",
    "        gt=30_000,\n",
    "        lt=70_000,\n",
    "        description=\"salary of the employee, the more senior the role, the higher salary\",\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"always include seniority level in the role (junior, senior, expert)\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"short description (max 2 sentences) of the role, include keywords\"\n",
    "    )\n",
    "\n",
    "\n",
    "result = await agent.run(\n",
    "    \"Give me an IT employee working as data engineer in Sweden\", output_type=Employee\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employee(name='Erik Karlsson', age=35, salary=65000, role='Senior Data Engineer', description='Designs, builds, and maintains scalable data pipelines and infrastructure. Expertise in ETL, data warehousing, and big data technologies.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee = result.output\n",
    "employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Designs, builds, and maintains scalable data pipelines and infrastructure. Expertise in ETL, data warehousing, and big data technologies.',\n",
       " 'Erik Karlsson')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee.description, employee.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(employee, BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Erik Karlsson',\n",
       " 'age': 35,\n",
       " 'salary': 65000,\n",
       " 'role': 'Senior Data Engineer',\n",
       " 'description': 'Designs, builds, and maintains scalable data pipelines and infrastructure. Expertise in ETL, data warehousing, and big data technologies.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"Erik Karlsson\",\"age\":35,\"salary\":65000,\"role\":\"Senior Data Engineer\",\"description\":\"Designs, builds, and maintains scalable data pipelines and infrastructure. Expertise in ETL, data warehousing, and big data technologies.\"}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"name\": \"Erik Karlsson\",\n",
      "   \"age\": 35,\n",
      "   \"salary\": 65000,\n",
      "   \"role\": \"Senior Data Engineer\",\n",
      "   \"description\": \"Designs, builds, and maintains scalable data pipelines and infrastructure. Expertise in ETL, data warehousing, and big data technologies.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(employee.model_dump_json(indent=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
